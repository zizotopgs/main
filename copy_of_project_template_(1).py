# -*- coding: utf-8 -*-
"""Copy_of_Project_Template (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H5JdsCExzmIDuPNyI2-mtRX5HZXqGmHb

# This notebook is prepared by ApplAi's Technical And Training Depratment.
- Please Don't use it outside the training without asking for permission as it's considered as Violation of Intellectual property rights

![ApplAi's Logo](https://media-exp1.licdn.com/dms/image/C4E0BAQHGLGltI2rzuQ/company-logo_200_200/0?e=2159024400&v=beta&t=adq8rNV09dPC6egdJMnfARt6Aq0TC9bSomFvFtm50WM)

### Task 1: Importing libraries and Exploring the Dataset.

### Task 2: Definining Exploratory Data Analysis with an overview of the whole project .

### Task 3: Checking missing values and Outliers & Creating visual methods to analyze the data.

### Task 4: creat a model that fits the data

### Task 5: creating an accurecy table

###

### Task 1: Importing libraries and Exploring the Dataset.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
df=pd.read_csv("/content/Company loan-20230829T092654Z-001.zip")

"""### Task 2: Definining Exploratory Data Analysis with an overview of the whole project"""

df.head(20)

df.info()

df.dtypes

df.isnull().sum()

NA_col = df.isnull().sum()
NA_col = NA_col[NA_col.values >(0.3*len(df))]
plt.figure(figsize=(20,4))
NA_col.plot(kind='bar')
plt.title('List of Columns & NA counts where NA values are more than 30%')
plt.show()

sns.catplot(data=df, x='RATE_ID_FOR_monthly_gross', y='INPUT_VALUE_ID_FOR_monthly_gross', kind='bar')

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

ax.scatter(df['PERCENT_OWN_owner_1'], df['PERCENT_OWN_owner_2'], df['PERCENT_OWN_owner_3'], c='blue', marker='o')

ax.set_title('3D Scatter Plot')
ax.set_xlabel('PERCENT_OWN_owner_1')
ax.set_ylabel('PERCENT_OWN_owner_2')
ax.set_zlabel('PERCENT_OWN_owner_3')


plt.show()

#analysis the data
sns.relplot(data=df, x='RATE_ID_FOR_location', y='location', kind='line')

plt.figure(figsize=(10, 6))

# Plotting each series with labels
plt.plot(df['completion_status'], df['PERCENT_OWN_owner_1'], label='PERCENT_OWN_owner_1', marker='o')
plt.plot(df['completion_status'], df['PERCENT_OWN_owner_2'], label='PERCENT_OWN_owner_2', marker='s')
plt.plot(df['completion_status'], df['PERCENT_OWN_owner_3'], label='PERCENT_OWN_owner_3', marker='^')

plt.title('Graph with Three Labeled Series')
plt.xlabel('completion_status')
plt.ylabel('Values')
plt.legend()  # Show the legend with labels
plt.grid(True)
plt.show()

number = []
for i in range(len(df)):
  cnt = 0
  if pd.isnull(df['owner_1_score'][i]) != True:
    cnt += 1
  if pd.isnull(df['owner_2_score'][i])!= True:
    cnt += 1
  if pd.isnull(df['owner_3_score'][i])!= True:
    cnt += 1
  number.append(cnt)

df['number'] = number

df=df.drop(columns=['RATE_ID_FOR_industry_type'],axis=1)
df=df.drop(columns=['RATE_ID_FOR_judgement_lien_time'],axis=1)
df=df.drop(columns=['INPUT_VALUE_ID_FOR_judgement_lien_time'],axis=1)
df=df.drop(columns=['RATE_ID_FOR_funded_last_30'],axis=1)
df=df.drop(columns=['RATE_ID_FOR_fsr'],axis=1)
df=df.drop(columns=['PERCENT_OWN_owner_3'],axis=1)
df=df.drop(columns=['CAP_AMOUNT_owner_3'],axis=1)
df=df.drop(columns=['RATE_owner_3'],axis=1)
df=df.drop(columns=['owner_3_score'],axis=1)
df=df.drop(columns=['deal_application_thread_id'],axis=1)
df=df.drop(columns=['id'],axis=1)
df=df.drop(columns=['Unnamed: 0'],axis=1)
df=df.drop(columns=['RATE_ID_FOR_avg_net_deposits'],axis=1)

df['owner_1_score'].fillna( df['owner_1_score'].mean() , inplace=True)
df['CAP_AMOUNT_owner_1'].fillna( df['CAP_AMOUNT_owner_1'].mean() , inplace=True)
df['PERCENT_OWN_owner_1'].fillna( df['PERCENT_OWN_owner_1'].mean() , inplace=True)
df['owner_2_score'].fillna( 0 , inplace=True)
df['CAP_AMOUNT_owner_2'].fillna( 0 , inplace=True)
df['PERCENT_OWN_owner_2'].fillna( 0 , inplace=True)
df['years_in_business'].fillna( df['years_in_business'].mean() , inplace=True)
df['fsr'].fillna( df['fsr'].mean() , inplace=True)
df['INPUT_VALUE_ID_FOR_tax_lien_count'].fillna( df['INPUT_VALUE_ID_FOR_tax_lien_count'].mean() , inplace=True)
df['INPUT_VALUE_ID_FOR_current_position'].fillna( df['INPUT_VALUE_ID_FOR_current_position'].mean() , inplace=True)
df['INPUT_VALUE_ID_FOR_avg_net_deposits'].fillna( df['INPUT_VALUE_ID_FOR_avg_net_deposits'].mean() , inplace=True)
df['INPUT_VALUE_owner_4'].fillna( df['INPUT_VALUE_owner_4'].mean() , inplace=True)
df['CAP_AMOUNT_owner_4'].fillna( df['CAP_AMOUNT_owner_4'].mean() , inplace=True)
df['PERCENT_OWN_owner_4'].fillna( df['PERCENT_OWN_owner_4'].mean() , inplace=True)

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df['RATE_owner_1'] = label_encoder.fit_transform(df['RATE_owner_1'])
df['RATE_owner_2'] = label_encoder.fit_transform(df['RATE_owner_2'])
df['location'] = label_encoder.fit_transform(df['location'])
df['RATE_ID_FOR_years_in_business'] = label_encoder.fit_transform(df['RATE_ID_FOR_years_in_business'])
df['RATE_ID_FOR_location'] = label_encoder.fit_transform(df['RATE_ID_FOR_location'])
df['RATE_ID_FOR_num_negative_days'] = label_encoder.fit_transform(df['RATE_ID_FOR_num_negative_days'])
df['RATE_ID_FOR_tax_lien_count'] = label_encoder.fit_transform(df['RATE_ID_FOR_tax_lien_count'])
df['RATE_ID_FOR_current_position'] = label_encoder.fit_transform(df['RATE_ID_FOR_current_position'])
df['INPUT_VALUE_ID_FOR_industry_type'] = label_encoder.fit_transform(df['INPUT_VALUE_ID_FOR_industry_type'])
df['RATE_owner_4'] = label_encoder.fit_transform(df['RATE_owner_4'])
df['completion_status'] = label_encoder.fit_transform(df['completion_status'])
df['funded_last_30'] = label_encoder.fit_transform(df['funded_last_30'])
df['RATE_ID_FOR_num_deposits'] = label_encoder.fit_transform(df['RATE_ID_FOR_num_deposits'])
df['RATE_ID_FOR_monthly_gross'] = label_encoder.fit_transform(df['RATE_ID_FOR_monthly_gross'])
df['RATE_ID_FOR_judgement_lien_amount'] = label_encoder.fit_transform(df['RATE_ID_FOR_judgement_lien_amount'])
df['RATE_ID_FOR_average_ledger'] = label_encoder.fit_transform(df['RATE_ID_FOR_average_ledger'])
df['RATE_ID_FOR_fc_margin'] = label_encoder.fit_transform(df['RATE_ID_FOR_fc_margin'])
df['RATE_ID_FOR_tax_lien_amount'] = label_encoder.fit_transform(df['RATE_ID_FOR_tax_lien_amount'])
df['RATE_ID_FOR_tax_lien_percent'] = label_encoder.fit_transform(df['RATE_ID_FOR_tax_lien_percent'])
df['RATE_ID_FOR_judgement_lien_percent'] = label_encoder.fit_transform(df['RATE_ID_FOR_judgement_lien_percent'])

sns.kdeplot(data=df, x='years_in_business')

sns.relplot(data=df, x='years_in_business', y='number', kind='line')

#displot data
for column in df.columns:
    plt.figure(figsize=(8, 6))
    sns.distplot(df[column], kde=True)
    plt.title(f'Distribution of {column}')
    plt.xlabel(column)
    plt.ylabel('Density')
    plt.show()

df.head()

"""### Task 3: Checking missing values and Outliers & Creating visual methods to analyze the data."""

df.head(20)

df.isnull().sum()

df.dtypes

#log for data because it is not normal distrbuted
df_log = df.applymap(lambda x: np.log(x))

from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.model_selection import cross_val_score
from sklearn.feature_selection import VarianceThreshold
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
x=df.drop(['completion_status'],axis=1)
y=df['completion_status']
x, y = make_classification()
x_data_kbest = SelectKBest(f_classif, k=8).fit_transform(x, y)
x_data_varth = VarianceThreshold(.9).fit_transform(x)

cross_val_score(LogisticRegression(), x, y, scoring='neg_log_loss').mean()

cross_val_score(LogisticRegression(), x_data_kbest, y, scoring='neg_log_loss').mean()

cross_val_score(LogisticRegression(), x_data_varth, y, scoring='neg_log_loss').mean()

X= df.drop(['completion_status'],axis=1)
y=df['completion_status']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x_data_kbest, y, test_size = 0.25, random_state = 41)

"""### Task 4: creat a model that fits the data"""

classifier = LogisticRegression(random_state = 0)

#fit data
classifier.fit(X_train, y_train)

#prediction
y_pred = classifier.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
cm

cr=classification_report(y_test, y_pred)
print(cr)

accuracy= accuracy_score(y_test, y_pred)
print(accuracy)

#using knn
model=KNeighborsClassifier(n_neighbors=5)
model.fit(X_train,y_train)

"""### Task 5: creating an accurecy table"""

y_preds=model.predict(X_test)

print(f"Testing score = {accuracy_score(y_test,y_preds)}")

#using randomforest
clf = RandomForestClassifier()

clf.fit(X_train, y_train)

Prepdictions = clf.predict(X_test)
print(predictions)

accuracyf= accuracy_score(y_test,Prepdictions )
print(accuracyf)

from sklearn.datasets import load_iris
import joblib

joblib_file = "job_placement_model"
joblib.dump(classifier, joblib_file)



loaded_model = joblib.load(open(joblib_file, 'rb'))

pred_Y = loaded_model.predict(X_test)
result = np.round(accuracy_score(y_test,y_pred) ,2)
print(result)
import pickle

file = "job_placement_model_pickle.pkl"
pickle.dump(classifier, open(file, 'wb'))

loaded_model = pickle.load(open(file, 'rb'))

pred_Y = loaded_model.predict(X_test)
result = np.round(accuracy_score(y_test, y_pred) ,2)
print(result)

#concloucion
#the perfect model is randomforest
#that has the best accuracy=0.84
#kbest is better than variance
#so we select feautures by kbest
#the is not normal distrbuted so we log it